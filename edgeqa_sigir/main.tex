% SIGIR 2026 Resources Track submission version.
% - Single-anonymous (author names listed).
% - 6 pages + unlimited references (appendices count toward 6 pages).
%
% The longer draft is kept as: main_full_review.tex

\documentclass[sigconf,natbib=true]{acmart}
\setcopyright{none}
\settopmatter{printacmref=false}
\renewcommand\footnotetextcopyrightpermission[1]{}

\usepackage{booktabs}
\usepackage{amsmath}
\usepackage{enumitem}
\usepackage{url}
\usepackage{graphicx}

\title[EdgeQA]{EdgeQA: Model-Aware Synthesis of Unknown and Brittle Knowledge Questions from Unlabeled Text with Knowledge Coverage Evaluation}

% -------------------------------------------------------------------
% Authors
% Replace with your real author list for single-blind tracks.
% For double-anonymous, keep only '\author{Anonymous}' and remove affiliations.

% Single-anonymous submission: list real authors.
\author{Yuli Zhang}
\affiliation{%
  \institution{Beijing University of Posts and Telecommunications}
  \city{Beijing}
  \country{China}
}
\email{zhangyuli@bupt.edu.cn}

\renewcommand{\shortauthors}{Zhang}

% -------------------------------------------------------------------
\begin{abstract}
Large language models (LLMs) perform well on many knowledge-intensive tasks, yet they remain unreliable in domains where their parametric knowledge is incomplete, long-tailed, or compositionally expressed.
We present \textbf{EdgeQA}, an \emph{API-only}, model-aware pipeline that converts unlabeled corpora into evidence-grounded QA pairs targeting \emph{unknown} and \emph{brittle} knowledge of a specified target model, and selects a budgeted subset to maximize \emph{document}, \emph{knowledge-unit}, and \emph{reasoning-type} coverage.
We additionally introduce \textbf{EdgeCoverBench}, a coverage-aware stress-test benchmark with paraphrases, near-miss counterfactuals, and unanswerable items to evaluate robustness and abstention.
In this resource release, we instantiate EdgeQA on two CC-BY textbooks (Open Logic Project; OpenStax University Physics), export BEIR-style retrieval collections (queries/corpus/qrels), and provide a coverage-and-cost evaluation suite for \textsc{DeepSeek-V3.2} (\texttt{deepseek-chat}) settings.
\end{abstract}

\keywords{information retrieval, evaluation, datasets, large language models, question answering}

% If you include CCS concepts, uncomment and fill these in.
% \begin{CCSXML}
% <ccs2012>
%  <concept>
%   <concept_id>10010147.10010257</concept_id>
%   <concept_desc>Computing methodologies~Information extraction</concept_desc>
%   <concept_significance>500</concept_significance>
%  </concept>
% </ccs2012>
% \end{CCSXML}
% \ccsdesc[500]{Computing methodologies~Information extraction}

\ccsdesc[500]{Information systems~Question answering}
\ccsdesc[500]{Information systems~Information retrieval}

\begin{document}

\maketitle

\input{sections/resources_paper}

\bibliographystyle{ACM-Reference-Format}
\bibliography{references}

\end{document}

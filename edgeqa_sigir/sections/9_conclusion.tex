\section{Conclusion}
\label{sec:conclusion}

We presented EdgeQA, a model-aware pipeline for constructing grounded QA resources that target unknown and brittle knowledge of a specified target model, and a coverage evaluation protocol that measures how comprehensively a generated QA set spans the underlying corpus.
We also described EdgeCoverBench, a coverage-aware stress-test benchmark with paraphrases, near-miss counterfactuals, and unanswerable items to evaluate robustness and abstention in an API-only setting.
We hope these resources and protocols make it easier to build and compare domain-specific QA/RAG datasets under clear coverage and cost constraints.
